import streamlit as st
import pandas as pd
import numpy as np
from sklearn.preprocessing import RobustScaler
import joblib

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="ì˜¤ì¼ ìƒíƒœ ì ê²€ ë°ëª¨", page_icon="â›‘ï¸")

st.title("â›‘ï¸ ì˜¤ì¼ ìƒíƒœ ì ê²€ ë°ëª¨")
st.write("ğŸ—¨ï¸ ê° ì»´í¬ë„ŒíŠ¸ì— ëŒ€í•´ ëœë¤ ê°’ì„ ë„£ê³  ì˜¤ì¼ ìƒíƒœë¥¼ ì ê²€í•©ë‹ˆë‹¤.")
st.write("ì•„ë˜ ë²„íŠ¼ì„ ëˆŒëŸ¬ ëœë¤ ê°’ì„ ìƒì„±í•˜ì—¬ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ í™•ì¸í•˜ì„¸ìš”.")

# Proba ë° ì˜ˆì¸¡ê²°ê³¼ í‘œ ìƒì„±
data = {
    "Proba": ["~0.40", "0.40~0.45", "0.45~0.50", "0.50~"],
    "ì˜ˆì¸¡ê²°ê³¼": ["ğŸŸ¢ ì •ìƒ", "ğŸŸ¡ ì£¼ì˜", "ğŸŸ  ê²½ê³ ", "ğŸ”´ ìœ„í—˜"]
}
tabel_side = pd.DataFrame(data)

# ì‚¬ì´ë“œë°”ì— í‘œ ì‚½ì…
st.sidebar.write("### ğŸš¦ì˜ˆì¸¡ ê²°ê³¼ì— ë”°ë¥¸ ìƒíƒœ")
st.sidebar.write(tabel_side.to_markdown(index=False), unsafe_allow_html=True)

# ì»´í¬ë„ŒíŠ¸ ëª©ë¡
components = ['COMPONENT1', 'COMPONENT2', 'COMPONENT3', 'COMPONENT4']

# ëœë¤ìœ¼ë¡œ ê°’ì„ ìƒì„±í•˜ê¸° ìœ„í•´ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
data = pd.read_csv("./data/casting.csv")

def load_model(model_path):
    return joblib.load(model_path)

def predict_fault(model, scaler, input_values, features):
    data = np.zeros((1, len(features)))
    for i, feature in enumerate(features):
        data[0, i] = input_values[i]
    data_scaled = scaler.transform(data)
    prediction = model.predict_proba(data_scaled)[:, 1]
    if prediction[0] < 0.40:
        return f"ğŸŸ¢ì •ìƒ: {prediction[0]:.2f} í™•ë¥ ë¡œ ë¶ˆëŸ‰ì…ë‹ˆë‹¤. ê³„ì† ì‚¬ìš©í•˜ì„¸ìš”."
    elif 0.40 <= prediction[0] < 0.45:
        return f"ğŸŸ¡ì£¼ì˜: {prediction[0]:.2f} í™•ë¥ ë¡œ ë¶ˆëŸ‰ì…ë‹ˆë‹¤. ì‚¬ìš©ì— ì£¼ì˜í•˜ì„¸ìš”."
    elif 0.45 <= prediction[0] < 0.50:
        return f"ğŸŸ ê²½ê³ : {prediction[0]:.2f} í™•ë¥ ë¡œ ë¶ˆëŸ‰ì…ë‹ˆë‹¤. ë§ˆìŒì˜ ì¤€ë¹„ê°€ í•„ìš”í•  ê²ƒ ê°™ìŠµë‹ˆë‹¤."
    else:
        return f"ğŸ”´ìœ„í—˜: {prediction[0]:.2f} í™•ë¥ ë¡œ ë¶ˆëŸ‰ì…ë‹ˆë‹¤. ë‹¹ì¥ êµì²´í•˜ì„¸ìš”."

# ëœë¤ ê°’ ìƒì„± í•¨ìˆ˜
def generate_random_values(features):
    random_values = np.random.rand(len(features))
    return dict(zip(features, random_values))

# í´ëŸ¬ìŠ¤í„°ì— ë”°ë¼ ëª¨ë¸ ê²½ë¡œ ê²°ì •
def get_model_path(cluster):
    return f"models/cat_3{chr(97+cluster)}_model.joblib"

# Streamlit ì•± ì‹¤í–‰
if st.button("ì˜¤ì¼ ìƒíƒœ ì ê²€"):
    predictions = []
    warning_components = []

    for component, model_name in zip(components, ['1', '2', '3', '4']):
        st.write(f"### {component}")

        # ë°ì´í„° ì¤€ë¹„
        component_data = data[data['COMPONENT_ARBITRARY'] == component]
        if not component_data.empty:  # Check if data is not empty
            if component in ['COMPONENT1', 'COMPONENT2', 'COMPONENT4']:
                component_data = component_data.drop(columns=['ID', 'COMPONENT_ARBITRARY', 'YEAR', 'SAMPLE_TRANSFER_DAY', 'U100', 'U75', 'U50', 'U25', 'U20', 'U14', 'U6', 'U4'])
                component_data['CD'] = component_data['CD'].fillna(component_data['CD'].mode()[0])
                component_data['K'] = component_data['K'].fillna(component_data['K'].mean())
            else:  # COMPONENT3
                component_data = component_data.drop(columns=['ID', 'COMPONENT_ARBITRARY', 'YEAR', 'SAMPLE_TRANSFER_DAY', 'U100', 'U75', 'U50', 'U25', 'U20', 'U14', 'U6', 'U4', 'CD'])
                component_data['K'] = component_data['K'].fillna(component_data['K'].mean())

            X = component_data
        else:
            st.write(f"{component}: ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            continue

        scaler = RobustScaler()
        X_scaled = scaler.fit_transform(X)

        # ëœë¤ ê°’ ìƒì„±
        input_values = generate_random_values(X.columns)

        if component == 'COMPONENT3':
            cluster = 0  # Assume cluster 0 as default
            # í´ëŸ¬ìŠ¤í„° ì˜ˆì¸¡ ë¡œì§ì„ ì—¬ê¸°ì— ì¶”ê°€í•˜ì—¬ cluster ê°’ì„ ì„¤ì •
            # ì—¬ê¸°ì„œëŠ” ì„ì‹œë¡œ cluster 0ìœ¼ë¡œ ì„¤ì •í–ˆìŠµë‹ˆë‹¤.
            model_path = get_model_path(cluster)
        else:
            model_path = f"models/cat_{model_name}_model.joblib"

        model = load_model(model_path)
        features = X.columns

        # ëœë¤ ê°’ì„ í‘œì‹œí•˜ëŠ” í† ê¸€
        expander_text = "ğŸ° ëœë¤ ê°’ ë³´ê¸°"
        with st.expander(expander_text):
            st.table(pd.DataFrame.from_dict(input_values, orient='index', columns=['ê°’']))

        prediction = predict_fault(model, scaler, list(input_values.values()), features)

        st.write(f"{component}: {prediction}")
        predictions.append(prediction)
        if "ìœ„í—˜" in prediction or "ê²½ê³ " in prediction:
            warning_components.append(component)

    if not warning_components:
        st.write("ğŸ¥³ëª¨ë“  ì»´í¬ë„ŒíŠ¸ì— ë¬¸ì œê°€ ì—†ìŠµë‹ˆë‹¤!")

    else:
        st.write(f"âš ï¸ì˜¤ì¼ êµì²´ê°€ í•„ìš”í•œ ì»´í¬ë„ŒíŠ¸: {', '.join(warning_components)}")