import streamlit as st
import pandas as pd
import numpy as np
from sklearn.preprocessing import RobustScaler
import joblib
from datetime import datetime

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="ì˜¤ì¼ ìƒíƒœ ì ê²€ ë°ëª¨", page_icon="â›‘ï¸")

st.title("âœï¸ë°ì´í„° ìˆ˜ì§‘ ë° ì¶•ì ")
st.write("ë°ì´í„°ë¥¼ ëª¨ì„ ìˆ˜ ìˆë„ë¡ ë„ì™€ë“œë¦½ë‹ˆë‹¤.")

# Proba ë° ì˜ˆì¸¡ê²°ê³¼ í‘œ ìƒì„±
data = {
    "Proba": ["~0.40", "0.40~0.45", "0.45~0.50", "0.50~"],
    "ì˜ˆì¸¡ê²°ê³¼": ["ğŸŸ¢ ì •ìƒ", "ğŸŸ¡ ì£¼ì˜", "ğŸŸ  ê²½ê³ ", "ğŸ”´ ìœ„í—˜"]
}
tabel_side = pd.DataFrame(data)

# ì‚¬ì´ë“œë°”ì— í‘œ ì‚½ì…
st.sidebar.write("### ğŸš¦ì˜ˆì¸¡ ê²°ê³¼ì— ë”°ë¥¸ ìƒíƒœ")
st.sidebar.write(tabel_side.to_markdown(index=False), unsafe_allow_html=True)

# ì»´í¬ë„ŒíŠ¸ ëª©ë¡
components = ['COMPONENT1', 'COMPONENT2', 'COMPONENT3', 'COMPONENT4']

# ëœë¤ìœ¼ë¡œ ê°’ì„ ìƒì„±í•˜ê¸° ìœ„í•´ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
data = pd.read_csv("./data/casting.csv")

# ë°ì´í„°í”„ë ˆì„ ì´ˆê¸°í™” ë˜ëŠ” ë¡œë“œ
if 'component_dfs' not in st.session_state:
    st.session_state.component_dfs = {component: pd.DataFrame(columns=['Date', 'Random_Values', 'Prediction']) for component in components}

component_dfs = st.session_state.component_dfs

def load_model(model_path):
    return joblib.load(model_path)

def predict_fault(model, scaler, input_values, features):
    data = np.zeros((1, len(features)))
    for i, feature in enumerate(features):
        data[0, i] = input_values[i]
    data_scaled = scaler.transform(data)
    prediction = model.predict_proba(data_scaled)[:, 1]
    return prediction[0]

# ëœë¤ ê°’ ìƒì„± í•¨ìˆ˜ (ë°ì´í„° ë¶„í¬ ê³ ë ¤)
def generate_random_values(component_data):
    random_values = {}
    for column in component_data.columns:
        if column in ['ID', 'COMPONENT_ARBITRARY', 'YEAR', 'SAMPLE_TRANSFER_DAY']:
            continue
        if component_data[column].dtype == 'object':
            random_values[column] = np.random.choice(component_data[column].dropna().values)
        else:
            mean = component_data[column].mean()
            std = component_data[column].std()
            random_values[column] = np.random.normal(mean, std)
    return random_values

# í´ëŸ¬ìŠ¤í„°ì— ë”°ë¼ ëª¨ë¸ ê²½ë¡œ ê²°ì • (ì„ì‹œë¡œ ì„¤ì •)
def get_model_path(cluster):
    return f"models/cat_3{chr(97+cluster)}_model.joblib"

# ë‚ ì§œ ì„ íƒ
selected_date = st.date_input("ì ê²€ ë‚ ì§œë¥¼ ì„ íƒí•˜ì„¸ìš”:", datetime.today())

# Streamlit ì•± ì‹¤í–‰
if st.button("ì˜¤ì¼ ìƒíƒœ ì ê²€"):
    for component, model_name in zip(components, ['1', '2', '3', '4']):
        st.write(f"### {component}")

        # ë°ì´í„° ì¤€ë¹„
        component_data = data[data['COMPONENT_ARBITRARY'] == component]
        if not component_data.empty:  # Check if data is not empty
            # Drop unnecessary columns
            component_data = component_data.drop(columns=['ID', 'COMPONENT_ARBITRARY', 'YEAR', 'SAMPLE_TRANSFER_DAY'])
            
            # Fill missing values and preprocess data
            component_data = component_data.fillna(component_data.mean())  # Fill missing values with mean

            X = component_data  # Use all columns as features

            scaler = RobustScaler()
            X_scaled = scaler.fit_transform(X)

            # ëœë¤ ê°’ ìƒì„±
            input_values = generate_random_values(component_data)

            if component == 'COMPONENT3':
                cluster = 0  # Assume cluster 0 as default
                # í´ëŸ¬ìŠ¤í„° ì˜ˆì¸¡ ë¡œì§ì„ ì—¬ê¸°ì— ì¶”ê°€í•˜ì—¬ cluster ê°’ì„ ì„¤ì •
                # ì—¬ê¸°ì„œëŠ” ì„ì‹œë¡œ cluster 0ìœ¼ë¡œ ì„¤ì •í–ˆìŠµë‹ˆë‹¤.
                model_path = get_model_path(cluster)
            else:
                model_path = f"models/cat_{model_name}_model.joblib"

            model = load_model(model_path)
            features = X.columns

            # ì˜ˆì¸¡ ê²°ê³¼
            prediction = predict_fault(model, scaler, list(input_values.values()), features)

            # ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ë°ì´í„°í”„ë ˆì„ì— ì¶”ê°€
            result_dict = {'Date': selected_date, 'Random_Values': input_values, 'Prediction': prediction}
            component_dfs[component] = component_dfs[component].append(result_dict, ignore_index=True)

            # ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ì•„ì´ì½˜ìœ¼ë¡œ ì‹œê°í™”
            status = "ğŸŸ¢ ì •ìƒ" if prediction < 0.25 else "ğŸŸ¡ ì£¼ì˜" if prediction < 0.5 else "ğŸŸ  ê²½ê³ " if prediction < 0.75 else "ğŸ”´ ìœ„í—˜"
            st.write(f"{component}: ì˜ˆì¸¡ ê²°ê³¼ - {status}")

    # ì„¸ì…˜ ìƒíƒœì— ë°ì´í„°í”„ë ˆì„ ì €ì¥
    st.session_state.component_dfs = component_dfs

# ëª¨ë“  ì»´í¬ë„ŒíŠ¸ì— ëŒ€í•œ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ë³´ì—¬ì¤Œ
with st.expander("ì „ì²´ ì˜ˆì¸¡ ê²°ê³¼ ë³´ê¸°"):
    st.write("ì „ì²´ ì˜ˆì¸¡ ê²°ê³¼:")
    for component, df in component_dfs.items():
        st.write(f"#### {component}")
        st.write(df)

# Probaë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ ì„  ê·¸ë˜í”„
selected_components = st.multiselect("ê·¸ë˜í”„ë¥¼ ë³´ê³  ì‹¶ì€ ì»´í¬ë„ŒíŠ¸ë¥¼ ì„ íƒí•˜ì„¸ìš”:", components)
if selected_components:
    st.write("### Prediction ê¸°ë°˜ ì„  ê·¸ë˜í”„")
    for component in selected_components:
        st.write(f"#### {component}")
        df = component_dfs[component].copy()
        df['Date'] = pd.to_datetime(df['Date'])
        df.set_index('Date', inplace=True)
        st.line_chart(df['Prediction'])
